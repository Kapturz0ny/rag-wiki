{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ee2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "DATA_PROCESSED_PATH = \"../data/processed\"\n",
    "FINETUNED_MODEL_PATH = \"../models/retriever_finetuned_bge_base\"\n",
    "\n",
    "WIKIPEDIA_CHUNKS_FILE = \"wikipedia_chunks_bge_base.jsonl\"\n",
    "CORPUS_EMBEDDINGS_FILE = \"corpus_embeddings_finetuned_bge_base.npy\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "wikipedia_chunks_path = os.path.join(DATA_PROCESSED_PATH, WIKIPEDIA_CHUNKS_FILE)\n",
    "corpus_embeddings_path = os.path.join(DATA_PROCESSED_PATH, CORPUS_EMBEDDINGS_FILE)\n",
    "\n",
    "if not os.path.exists(wikipedia_chunks_path):\n",
    "    raise FileNotFoundError(f\"Wikipedia chunks file not found: {wikipedia_chunks_path}\")\n",
    "if not os.path.exists(FINETUNED_MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"Fine-tuned retriever not found: {FINETUNED_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriver loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ccd6dac89e48c78e01ecaa89e2c503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading corpus passages: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36508 corpus passages.\n"
     ]
    }
   ],
   "source": [
    "retriever_model = SentenceTransformer(FINETUNED_MODEL_PATH, device=DEVICE)\n",
    "print(\"Retriever loaded.\")\n",
    "\n",
    "corpus_passages_data = []\n",
    "corpus_passage_texts = []\n",
    "\n",
    "with open(wikipedia_chunks_path, 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f, desc=\"Loading corpus passages\"):\n",
    "        record = json.loads(line)\n",
    "        if 'passage_id' in record and 'passage_text' in record and record['passage_text'].strip():\n",
    "            corpus_passages_data.append(record)\n",
    "            corpus_passage_texts.append(record['passage_text'])\n",
    "        else:\n",
    "            print(f\"Warning: Skipping invalid record: {record}\")\n",
    "\n",
    "print(f\"Loaded {len(corpus_passages_data)} corpus passages.\")\n",
    "if not corpus_passages_data:\n",
    "    raise ValueError(\"No corpus passages loaded. Check the wikipedia_chunks_bge_base.jsonl file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48095a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing embeddings from: ../data/processed/corpus_embeddings_finetuned_bge_base.npy\n",
      "Passages order in saved file matches the order of loaded corpus.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(corpus_embeddings_path):\n",
    "    print(f\"Loading existing embeddings from: {corpus_embeddings_path}\")\n",
    "    corpus_embeddings = np.load(corpus_embeddings_path)\n",
    "    \n",
    "    if corpus_embeddings.shape[0] == len(corpus_passages_data):\n",
    "        print(f\"Loaded {corpus_embeddings.shape[0]} embeddings, matching the number of loaded passages.\")\n",
    "    else:\n",
    "        print(f\"WARNING: Number of loaded embeddings ({corpus_embeddings.shape[0]}) \"\n",
    "              f\"does not match number of loaded passages ({len(corpus_passages_data)}). \"\n",
    "              f\"Embeddings will be recalculated.\")\n",
    "        corpus_embeddings = None\n",
    "else:\n",
    "    corpus_embeddings = None\n",
    "\n",
    "if corpus_embeddings is None:\n",
    "    corpus_embeddings = retriever_model.encode(\n",
    "        corpus_passage_texts, \n",
    "        show_progress_bar=True, \n",
    "        convert_to_numpy=True,\n",
    "        batch_size=128 \n",
    "    )\n",
    "    print(f\"Calculated embeddings for corpus. Shape: {corpus_embeddings.shape}\")\n",
    "\n",
    "    np.save(corpus_embeddings_path, corpus_embeddings)\n",
    "    print(f\"Embeddings saved to: {corpus_embeddings_path}.\")\n",
    "\n",
    "\n",
    "if isinstance(corpus_embeddings, torch.Tensor):\n",
    "    corpus_embeddings = corpus_embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca554128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_corpus(query_text, top_k=5):\n",
    "    \"\"\"\n",
    "    Gives top-k similar passages to the asked quesiton \n",
    "    \"\"\"\n",
    "    if not query_text.strip():\n",
    "        print(\"Empty qustion\")\n",
    "        return []\n",
    "    \n",
    "    query_embedding = retriever_model.encode(query_text, convert_to_numpy=True)\n",
    "    \n",
    "    if query_embedding.ndim == 1:\n",
    "        query_embedding = query_embedding.reshape(1, -1)\n",
    "        \n",
    "    cosine_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_k_indices_unsorted = np.argpartition(-cosine_scores, range(top_k))[:top_k]\n",
    "    top_k_indices = top_k_indices_unsorted[np.argsort(-cosine_scores[top_k_indices_unsorted])]\n",
    "\n",
    "    results = []\n",
    "    for i, idx in enumerate(top_k_indices):\n",
    "        passage_info = corpus_passages_data[idx]\n",
    "        results.append({\n",
    "            \"rank\": i + 1,\n",
    "            \"score\": float(cosine_scores[idx]),\n",
    "            \"passage_id\": passage_info.get('passage_id'),\n",
    "            \"text\": passage_info.get('passage_text'),\n",
    "            \"document_title\": passage_info.get('document_title', 'N/A')\n",
    "        })\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_found_passages(results):\n",
    "\tfor result in results:\n",
    "\t\tprint(f\"  Rank {result['rank']}: Score={result['score']:.4f}, DocTitle='{result['document_title']}', PassageID='{result['passage_id']}'\")\n",
    "\t\tprint(f\"    Fragment: \\\"{result['text']}\\\"\")\n",
    "\t\tprint(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd190f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m test_query_1 = \u001b[33m\"\u001b[39m\u001b[33mWhen did the French Revolution start?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m retrieved_docs_1 = search_corpus(test_query_1, top_k=\u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mprint_found_passages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieved_docs_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m test_query_2 = \u001b[33m\"\u001b[39m\u001b[33mWhat is the capital of Poland?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mprint_found_passages\u001b[39m\u001b[34m(results)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_found_passages\u001b[39m(results):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrank\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Score=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, DocTitle=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mdocument_title\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, PassageID=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mpassage_id\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Fragment: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# example retriver usage\n",
    "\n",
    "test_query_1 = \"When did the French Revolution start?\"\n",
    "retrieved_docs_1 = search_corpus(test_query_1, top_k=3)\n",
    "print_found_passages(retrieved_docs_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "test_query_2 = \"What is the capital of Poland?\"\n",
    "retrieved_docs_2 = search_corpus(test_query_2, top_k=3)\n",
    "print_found_passages(retrieved_docs_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "test_query_3 = \"Who painted the Mona Lisa?\"\n",
    "retrieved_docs_3 = search_corpus(test_query_3, top_k=3)\n",
    "print_found_passages(retrieved_docs_3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "test_query_4 = \"Who is the biggest exporter of copper?\"\n",
    "retrieved_docs_4 = search_corpus(test_query_4, top_k=3)\n",
    "print_found_passages(retrieved_docs_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
